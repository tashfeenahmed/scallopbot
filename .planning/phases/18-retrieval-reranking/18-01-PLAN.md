---
phase: 18-retrieval-reranking
plan: 01
type: tdd
---

<objective>
Implement LLM-based re-ranking function that scores search result relevance to a query.

Purpose: The current hybrid search (BM25 0.4 + semantic 0.4 + prominence 0.2) relies on lexical and vector similarity, missing semantic nuance. An LLM re-ranker evaluates whether each candidate actually answers the query, pushing recall from ~71% to ~87%.
Output: Tested `rerankResults()` function with clear input/output contract.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/references/tdd.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Key source files:
@src/memory/scallop-store.ts
@src/memory/bm25.ts
@src/memory/embeddings.ts
@src/providers/types.ts

**Tech stack available:** Vitest, TypeScript, existing LLMProvider interface
**Established patterns:**
- LLM calls via `provider.complete()` returning `CompletionResponse`
- JSON output parsing from LLM (see fact-extractor.ts pattern)
- Hybrid search returns `ScallopSearchResult[]` with memory, score, matchType
**Constraining decisions:**
- SEARCH_WEIGHTS { keyword: 0.4, semantic: 0.4, prominence: 0.2 } — re-ranker augments, doesn't replace
- Groq available for fast tier (cheap re-ranking), Anthropic for capable tier
</context>

<feature>
  <name>LLM Re-ranker for memory search results</name>
  <files>src/memory/reranker.ts, src/memory/reranker.test.ts</files>
  <behavior>
    rerankResults(query, candidates, provider) → reranked results with adjusted scores

    Input:
    - query: string (user's search query)
    - candidates: Array of { content: string, originalScore: number, id: string }
    - provider: LLMProvider (for making the scoring call)
    - options?: { maxCandidates?: number, timeoutMs?: number }

    Output:
    - Array of { id: string, relevanceScore: number, originalScore: number, finalScore: number }
    - Sorted by finalScore descending
    - finalScore = (originalScore * 0.4) + (llmRelevanceScore * 0.6)

    Cases:
    - 5 candidates, query "wife's food preferences" →
      "Wife likes sushi" gets high LLM score (0.9), "Lives in Dublin" gets low (0.1)
    - Empty candidates → returns empty array
    - LLM call fails → returns candidates with original scores unchanged (graceful fallback)
    - >20 candidates → truncates to maxCandidates (default 20) before LLM call
    - LLM returns malformed JSON → graceful fallback to original scores
    - Single candidate → still re-ranks (LLM confirms relevance)

    LLM Prompt Design:
    - System: "Score each memory's relevance to the query on 0.0-1.0 scale"
    - Present query + numbered candidates
    - Request JSON array of scores: [{ index: number, score: number }]
    - Use low temperature (0.1) for consistency
    - Keep prompt compact — memories are short strings (<100 chars typically)

    Score Blending:
    - finalScore = (originalScore × 0.4) + (llmRelevanceScore × 0.6)
    - LLM score dominates because it captures semantic understanding
    - Original score provides fallback signal (BM25+semantic+prominence)
    - Threshold: drop results with finalScore < 0.05
  </behavior>
  <implementation>
    Create src/memory/reranker.ts with:
    1. RerankOptions interface (maxCandidates, timeoutMs)
    2. RerankCandidate interface (id, content, originalScore)
    3. RerankResult interface (id, relevanceScore, originalScore, finalScore)
    4. rerankResults() async function
    5. buildRerankPrompt() helper — formats query + candidates for LLM
    6. parseRerankResponse() helper — extracts scores from LLM JSON response
    7. Graceful fallback: if LLM fails, return original scores as finalScore

    Keep the re-ranker stateless — no class needed. Pure functions that take an LLMProvider.
    Use the existing CompletionRequest format from src/providers/types.ts.

    DO NOT:
    - Create a new provider abstraction — use existing LLMProvider directly
    - Cache re-ranking results — each query context is unique
    - Use streaming — we need full JSON response
    - Add retry logic — single attempt with graceful fallback is sufficient
  </implementation>
</feature>

<verification>
npm test -- src/memory/reranker.test.ts
</verification>

<success_criteria>
- Failing test written and committed (RED)
- Implementation passes all tests (GREEN)
- Refactor complete if needed (REFACTOR)
- All 2-3 commits present
- rerankResults() handles: normal case, empty input, LLM failure, malformed response, truncation
- Score blending formula: finalScore = originalScore * 0.4 + llmScore * 0.6
</success_criteria>

<output>
After completion, create `.planning/phases/18-retrieval-reranking/18-01-SUMMARY.md`
</output>
